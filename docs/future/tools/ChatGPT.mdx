---
tags: [LLaMA, ChatGPT, HowardZhangdqs]
description: 大语言模型推荐
sidebar_position: 10
---

# 大语言模型推荐

```mdx-code-block

import { UrlTable } from "@site/src/components/PingList";

```

```mdx-code-block

export const Base64_style = {
    color: "var(--ifm-color-primary)",
    opacity: "0.7",
    fontSize: "50%",
};

export const Base64 = (prop) => {
    try {
        let res = window.decodeURI(window.atob(prop.str));
        return <p>{res}<div style={Base64_style}>本段文字解密成功，密文长度：{prop.str.length}，明文长度：{res.length}</div></p>;
    } catch {
        return <p><div style={{...Base64_style, color: "red"}}>本段文字解密失败，密文内容："{prop.str}"</div></p>;
    }
};

```

[猜你想要 - 某最早出现的大语言模型的代理 <IconExternalLink/>](#gpt)

## 国外大语言模型

以下为截至2023年3月，出现的国外大语言模型。

<table style={{textAlign: "center"}}>
<thead>
<tr><th>名称</th><th>出品机构</th><th>参数量</th><th>类型</th><th>备注</th></tr>
</thead>
<tbody>
<tr><td>LLaMA</td><td>Meta AI</td><td>7B-65B</td><td>Decoder</td><td>开源</td></tr>
<tr><td>OPT</td><td>Meta AI</td><td>125M-175B</td><td>Decoder</td><td>开源</td></tr>
<tr><td>T5</td><td>Google</td><td>220M-11B</td><td>Encoder-Decoder</td><td>开源</td></tr>
<tr><td>mT5</td><td>Google</td><td>235M-13B</td><td>Encoder-Decoder</td><td>开源</td></tr>
<tr><td>UL2</td><td>Google</td><td>20B</td><td>Encoder-Decoder</td><td>开源</td></tr>
<tr><td>PaLM</td><td>Google</td><td>540B</td><td>Decoder</td><td>闭源</td></tr>
<tr><td>LaMDA</td><td>Google</td><td>2B-137B</td><td>Decoder</td><td>闭源</td></tr>
<tr><td>FLAN-T5</td><td>Google</td><td>同T5</td><td>Encoder-Decoder</td><td>开源</td></tr>
<tr><td>FLAN-UL2</td><td>Google</td><td>同U2</td><td>Encoder-Decoder</td><td>开源</td></tr>
<tr><td>FLAN-PaLM</td><td>Google</td><td>同PaLM</td><td>Decoder</td><td>闭源</td></tr>
<tr><td>FLAN</td><td>Google</td><td>同LaMDA</td><td>Decoder</td><td>闭源</td></tr>
<tr><td>BLOOM</td><td>BigScience</td><td>176B</td><td>Decoder</td><td>开源</td></tr>
<tr><td>T0</td><td>BigScience</td><td>3B</td><td>Decoder</td><td>开源</td></tr>
<tr><td>BLOOMZ</td><td>BigScience</td><td>同BLOOM</td><td>Decoder</td><td>开源</td></tr>
<tr><td>mT0</td><td>BigScience</td><td>同T0</td><td>Decoder</td><td>开源</td></tr>
<tr><td>GPT-Neo</td><td>EleutherAI</td><td>125M-2.7B</td><td>Decoder</td><td>开源</td></tr>
<tr><td>GPT-NeoX</td><td>EleutherAI</td><td>20B</td><td>Decoder</td><td>开源</td></tr>
<tr><td>GPT3</td><td>OpenAI</td><td>175B (davinci)</td><td>Decoder</td><td>闭源</td></tr>
<tr><td>GPT4</td><td>OpenAI</td><td>unknown</td><td>OpenAI</td><td>闭源</td></tr>
<tr><td>InstructGPT</td><td>OpenAI</td><td>1.3B</td><td>Decoder</td><td>闭源</td></tr>
<tr><td>Alpaca</td><td>Stanford</td><td>LLaMA</td><td>Decoder</td><td>开源</td></tr>
</tbody>
</table>

## 国内大语言模型

### 开源

<table style={{textAlign: "center"}}>
<thead>
<tr><th>名称</th><th>出品机构</th><th>参数量</th><th>基座模型</th></tr>
</thead>
<tbody>
<tr><td>ChatGLM-6B</td><td>清华大学</td><td>6.2B</td><td>自研</td></tr>
<tr><td>CPM-Bee</td><td>清华大学 - OpenBMB</td><td>6.2B</td><td>自研</td></tr>
<tr><td>Chinese-ChatLLaMA</td><td></td><td>33B</td><td>自研</td></tr>
<tr><td>RWKV-LM</td><td><a href="https://www.zhihu.com/people/bopengbopeng">@PENG Bo</a></td><td>0.1-14B</td><td>自研，基于RNN</td></tr>
<tr><td>Chinese-Vicuna</td><td></td><td>7B-65B</td><td>LLaMA 7B</td></tr>
<tr><td>Chinese-LLaMA-Alpaca</td><td></td><td>7B-65B</td><td>LLaMA 7B</td></tr>
<tr><td>Luotuo-Chinese-LLM</td><td></td><td>6.2B</td><td>ChatGLM-6B</td></tr>
</tbody>
</table>

如有本地部署需要，推荐 [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) 与 [RWKV-LM](https://github.com/BlinkDL/RWKV-LM)（亲测可以顺利在本地部署）。

### 闭源

国内闭源大语言模型相对落后于国外，有些效果较好的甚至被怀疑是否为套壳。

<table style={{textAlign: "center"}}>
<thead>
<tr><th>名称</th><th>出品机构</th><th>备注</th></tr>
</thead>
<tbody>
<tr><td><a href="https://tongyi.aliyun.com/">通义千问</a></td><td>阿里巴巴</td><td>已有社员取得内测资格</td></tr>
<tr><td><a href="https://yiyan.baidu.com/">文心一言</a></td><td>百度</td><td>已有社员取得内测资格</td></tr>
<tr><td><a href="https://www.baai.ac.cn/portal/article/index/cid/49/id/518.html">悟道</a></td><td>智源</td><td></td></tr>
<tr><td><a href="https://chat.sensetime.com/wb/">商量</a></td><td>商汤</td><td></td></tr>
<tr><td><a href="https://www.so.com/zt/invite.html">360智脑</a></td><td>360</td><td></td></tr>
<tr><td><a href="https://tiangong.kunlun.com/">天工</a></td><td>昆仑万维、奇点智源</td><td></td></tr>
<tr><td><a href="https://www.baai.ac.cn/portal/article/index/cid/49/id/518.html">悟道</a></td><td>智源</td><td></td></tr>
<tr><td><a href="https://xinghuo.xfyun.cn/">星火认知大模型</a></td><td>科大讯飞</td><td>已有社员取得内测资格</td></tr>
<tr><td><a href="https://moss.fastnlp.top/">MOSS</a></td><td>复旦大学</td><td></td></tr>
<tr><td>知海图AI</td><td>知乎</td><td></td></tr>
<tr><td>盘古大模型</td><td>华为</td><td></td></tr>
<tr><td>混元</td><td>腾讯</td><td></td></tr>
<tr><td>混元</td><td>腾讯</td><td></td></tr>
<tr><td>玉言</td><td>网易</td><td></td></tr>
<tr><td>ChatJD</td><td>京东</td><td></td></tr>
</tbody>
</table>


## 某最早出现的大语言模型的代理 {#gpt}


<Base64 str='JUU4JUJGJTk5JUU5JTg3JThDJUU3JTlBJTg0JUU0JUJCJUEzJUU3JTkwJTg2JUU2JTk4JUFGJUU2JThDJTg3JUU0JUI4JTgwJUU0JUJBJTlCJUU0JUJEJTlDJUU4JTgwJTg1JUU1JThGJTk2JUU1JUJFJTk3JUU0JUJBJTg2JUU1JTlCJUJEJUU5JTk5JTg1JUU0JUJBJTkyJUU4JTgxJTk0JUU3JUJEJTkxJUU4JUFFJUJGJUU5JTk3JUFFJUU2JTlEJTgzJUU5JTk5JTkwJUVGJUJDJThDJUU1JTkwJTkxJUU2JUIyJUExJUU2JTlDJTg5JUU1JThGJTk2JUU1JUJFJTk3JUU3JTlCJUI4JUU1JUJBJTk0JUU2JTlEJTgzJUU5JTk5JTkwJUU3JTlBJTg0JUU0JUJBJUJBJUU2JThGJTkwJUU0JUJFJTlCJUU2JTk3JUEwJUU1JTgxJUJGJUU2JTg4JTk2JUU2JTlDJTg5JUU1JTgxJUJGJUU3JTlBJTg0JUU2JTlDJThEJUU1JThBJUExJUUzJTgwJTgyJUU4JUJGJTk5JUU5JTg3JThDJUU2JTk0JUI2JUU1JUJEJTk1JUU3JTlBJTg0JUU0JUJCJUEzJUU3JTkwJTg2JUU1JUE0JUE3JUU1JUE0JTlBJUU0JUI4JThEJUU3JTk0JUE4JUU3JTk5JUJCJUU5JTk5JTg2JUU0JUI4JTk0JUU1JUFFJThDJUU1JTg1JUE4JUU1JTg1JThEJUU4JUI0JUI5JUUzJTgwJTgyJUU1JTlDJUE4JUU4JUJGJTk5JUU5JTg3JThDJUU2JTg4JTkxJUU1JTkxJUJDJUU1JTkwJTgxJUU1JUE0JUE3JUU1JUFFJUI2JUU1JUFGJUI5JUU0JUJEJUJGJUU3JTk0JUE4JUU0JUJBJTg2JUU3JTlBJTg0JUU1JTg1JThEJUU4JUI0JUI5JUU0JUJCJUEzJUU3JTkwJTg2JUU2JThGJTkwJUU0JUJFJTlCJUU2JThEJTkwJUU4JUI1JUEwJUVGJUJDJThDJUU4JUJGJTk5JUU2JUEwJUI3JUU2JTg4JTkxJUU0JUJCJUFDJUU2JTg5JThEJUU4JTgzJUJEJUU2JTlCJUI0JUU1JThGJUFGJUU2JThDJTgxJUU3JUJCJUFEJUU1JTlDJUIwJUU0JUJEJUJGJUU3JTk0JUE4JUU1JUFFJTgzJUU0JUJCJUFDJUUzJTgwJTgy'/>

:::info 注意

由于浏览器安全策略限制，ping结果可能有误，具体请依照实际使用情况为准。

:::

<UrlTable />